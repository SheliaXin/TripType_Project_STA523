---
output: html_document
---

Final Project Write-Up
========================================================
###Team Members' Names: 
###Sarah Normoyle, Gonzalo Bustos, Xin Xu, Arpita Mandan, Drew Jorda, Yuan Gao


##Introduction

The data set and problem set up for this project is provided by [kaggle.com] (https://www.kaggle.com/c/walmart-recruiting-trip-type-classification) . From this website, "Walmart uses both art and science to continually make progress on their core mission of better understanding and serving their customers. One way Walmart is able to improve customers' shopping experiences is by segmenting their store visits into different trip types." A motivation for the statistical analysis in this project is to provide a company like Walmart with interesting information  and insights regarding their customers. The kaggle competition includes a training and a testing set where the goal is to classify different types of shopping trips in the testing set with information provided in the training set. 

##Data 

The data has transactional data for customers shopping at Walmart. 

The data consists of 7 columns: TripType, VisitNumber, Weekday, Upc, ScanCount, DepartmentDescription, and FinelineNumber. The TripType is an id that represents the type of trip the customer made. This is the variable we are going to be predicting. The VisitNumber is an id depicting a trip made by a customer. Weekday is the weekday of the trip. UPC which is the Unique Product Code is the unique code associated with the product. ScanCount is the quantity of that particular item bought. A negative value here means the item was returned. DepartmentDescription is a broad description of the item's department. FinelineNumber is a more refined category for each of the products, created by Walmart.

We explored the UPC. The length varies from 4 to 12, but is mostly either 10, 11 or 12. The first five digits when the length is 10, and digits 2 to 6 when the length is 11 or 12 stand for the Manufacturer code. The next 2 stand for the Family code, and the next 3 for the Value code of the item. We could use this to see that within a Department which manufacturer is the most popular. The value code gives an idea of the coupon associated with the item. 

Each shopping trip is categorised based on the items purchased in each trip. For example: a trip may be small daily dinner trip, a weekly large grocery trip, or a holiday trip.

There's two sets of data: the training set and the test set. The training set contains the trips with the TripType included. There are a total of 38 distinct trip types that Walmart has come up with. And the data has 65,535 rows.

Using the columns in the Test data, we need to come up with categorising/clustering the test data into trip types. And finally predict a TripType for each of the customer trips in the test data.


##Data Visualilzation and Shiny App

First, we looked at different ways to visualize the datasets. The Shiny App contains three different plots where various inputs can be changed, and the plots will automatically change. The Shiny App can be found online on RStudio's hosting service for Shiny apps here: [Shiny App] (https://snormoyle.shinyapps.io/Final_Project_STA523). In all three plots, the dataset can be chosen as the training set, the testing set or uploading file. The step that takes the longest to load in the App is selecting one of these two datasets(training/testing set) because they have almost 700,000 rows each. Descriptions of the three different plots are as follows:


1. Basket Size by Day Bargraph: 

For this plot, the user can select a minimum basket size and a maximum basket size. This plot was intended to be able to look to see during which days of the week people shop most often and also to see if this changes for different types of shopping trips. We hypothesize that people in general shop more often on the weekdays, and in addition, people shop more often for big baskets on the weekends.  

This bargraph shows the proportion of the all trips on that day next to the proportion with that specified basket size that occured on that day. You can see how the propotion with the specified basket changes compared to the total proportion. Is it seen that overall, most people shop on weekdays, and in addition, a greater proportion shops for big baskets on weekends. Negative items or baskets sizes are returns. 


2. Department by Weekday Bargraph: 

For this plot, the user can either select all the departemtn or can select the desired departments. The total heights of this bargraph shows the total frequency of items bought per weekdays. The stacked colors of each bargraph show the proportion of the different selected deparments. The user can see how the proportion of items bought from different departments changes on different weekdays.  

3. Department Relationship Chart:

On this plot, the user can select the different desired departments. This plot shows the relationship between the departments and how often people buy items in those departments at the same time. On the x and y axis are the selected departments creating a matrix between all the selected departments. The shaded sqaures within this matrix show the relationship between them. The darker the shade of blue, the more related those departments are and the more often customers buy products from those different departments. 


##Cleaning and Organzing Data

Since in our original train/test set each row represents a product bought by someone, each visit number may correspond to several rows. To classify the visit number, we cleaned and reorganized the data. The data for each visit number is now: 

1. visit number
2. number of purchases
3. number of returns
4. weekday
5. indicators for the specific departments for the trip
6. indicators for the fine line numbers for the trip, which is a more descriptive categorizing number than the department for each item

##Classification and Prediction 

To classify the trips and the visit numbers, we used the SVM algorithm.

### Support Vector Machine Models

Support Vector Machine(SVM) is an algorithm used for classification and regression analysis. It construct a linear boundary in a large, transformed version of the feature space to produce nolinear boundaries for classification[1].

We build up two SVM models using both "linear" kernel and "radial" kernel, and set the cost=10. The misclassification error in "linear" kernel model is 34.81\%. With using "linear" kernel and the misclassification error is 33.87\%. 

Third, we use our SVM models to predict the trip type in test set and upload our result to Kaggle. The model with "radial" kernel gets better performance than the "linear" kernel model.

The submissions to kaggle can be found in submssion.csv and submission_r.csv. 

## Inprovement and discussion

To improve our Support Vector Machine Models, we could use tuning to set our parameter `cost`, `gamma` in the model. We could also try to incorporate the FineLineNumber into our model. We first attempted to try to incorporate it, but it wasn't working with our framework. There are also possibly other variables that could be provided to make our model better at classifying on predicting.

This project further practice our R skills, helped with learning about classification algorithms, and furthured improved our knowledge of using the Shiny App. In addition, we learned more about kaggle.com, and all of the cool projects that are going on there.

## Reference
[1] Support Vector Machine. (n.d.). In The elements of statistical learning: Data mining, inference, and prediction (Second ed.). (p. 417).

[2] Support Vector Machines. (n.d.). Retrieved December 12, 2015, from http://rstatistics.net/support-vector-machines/ 


